{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:54:13.828147Z",
     "start_time": "2019-02-28T18:54:13.783321Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import calendar\n",
    "import operator\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "import clv_scoring_functions\n",
    "##(make sure our CLV scoring functions script is accessible)\n",
    "import glob\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import sklearn as sklearn\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import minimize, rosen, rosen_der\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:54:14.524604Z",
     "start_time": "2019-02-28T18:54:14.516282Z"
    }
   },
   "outputs": [],
   "source": [
    "from dateutil import rrule\n",
    "\n",
    "def weeks_between(start_date, end_date):\n",
    "    weeks = rrule.rrule(rrule.WEEKLY, dtstart=start_date, until=end_date)\n",
    "    return weeks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:54:15.227785Z",
     "start_time": "2019-02-28T18:54:15.220541Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_years(d, years):\n",
    "    \"\"\"Return a date that's `years` years after the date (or datetime)\n",
    "    object `d`. Return the same calendar date (month and day) in the\n",
    "    destination year, if it exists, otherwise use the following day\n",
    "    (thus changing February 29 to March 1).\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return d.replace(year = d.year + years)\n",
    "    except ValueError:\n",
    "        return d + (date(d.year + years, 1, 1) - date(d.year, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:54:18.033053Z",
     "start_time": "2019-02-28T18:54:18.022741Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-17-048624321137>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-048624321137>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#Format our date inputs  \n",
    "if str(type(end_date)) != \"<class 'pandas._libs.tslibs.timestamps.Timestamp'>\":\n",
    "    print(type(start_date))\n",
    "    i = str(start_date)\n",
    "    try:\n",
    "        dt_start = datetime.datetime.strptime(i, '%Y/%m/%d')\n",
    "    except ValueError:\n",
    "        print(\"Incorrect start format\")\n",
    "\n",
    "    i = str(end_date)    \n",
    "    try:\n",
    "        dt_end = datetime.datetime.strptime(i, '%Y/%m/%d')\n",
    "    except ValueError:\n",
    "        print(\"Incorrect start format\")\n",
    "\n",
    "#Formatting the dates for SQL \n",
    "        dt_start = str(dt_start) + str('.000')\n",
    "        dt_end = str(dt_end) + str('.000')\n",
    "else: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:54:20.617154Z",
     "start_time": "2019-02-28T18:54:20.599507Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SQL_Query(start_date, end_date, UID, password ):\n",
    "\n",
    "    dt_start= start_date\n",
    "    dt_end = end_date    \n",
    "\n",
    "\n",
    "#Establish our connection to the server \n",
    "    conn_string = 'DRIVER=/usr/local/lib/libtdsodbc.so;SERVER=wnj-datasizesql;PORT=1433;DATABASE=Data Analytics;UID={};PWD={}'.format(UID,password)\n",
    "    conn = pyodbc.connect(conn_string)\n",
    "\n",
    "#Run our sql query\n",
    "\n",
    "    query = (\"\"\"\n",
    "    SELECT b.customer_id,\n",
    "    round(b.recency + b.frequency/10 + b.AmountPerWeek/100, 2)AS RFM,\n",
    "    b.recency, b.frequency, b.T, \n",
    "    b.order_count,\n",
    "    b.total_amount,\n",
    "    b.FirstOrderDate, b.LastOrderDate\n",
    "    FROM\n",
    "      (\n",
    "\n",
    "        SELECT\n",
    "          a.customer_id,\n",
    "          a.order_count,\n",
    "          a.recency,\n",
    "          a.frequency,\n",
    "          a.T,\n",
    "          round(a.total_amount /isnull(NULLIF(a.frequency, 0), 1), 2)AS AmountPerWeek,\n",
    "          a.total_amount,\n",
    "          a.FirstOrderDate,\n",
    "          a.LastOrderDate\n",
    "        FROM\n",
    "          (\n",
    "            SELECT\n",
    "              cbs.customer_identifier AS customer_id,\n",
    "              count(DISTINCT cast(DATEPART(WK, td.transaction_date)AS VARCHAR)+cast(year(td.transaction_date)AS VARCHAR))- 1\n",
    "              AS frequency,\n",
    "\n",
    "              datediff(WEEK,MIN(td.transaction_date),MAX(\n",
    "                  td.transaction_date))AS recency,\n",
    "              datediff(WEEK,MIN(td.transaction_date),\n",
    "                       getdate())    AS T,\n",
    "              count(distinct(td.av_transaction_id))as order_count,\n",
    "              MIN(\n",
    "                  td.transaction_date)  AS FirstOrderDate,\n",
    "              MAX(\n",
    "                  td.transaction_date)  AS LastOrderDate,\n",
    "              round(SUM((td.gross_line_amount - td.pos_discount_amount)),2) AS total_amount\n",
    "            FROM transaction_detail\n",
    "              as td\n",
    "              INNER JOIN customer_basket_scv_2017 AS cbs  ON\n",
    "                td.av_transaction_id = cbs.transaction_id\n",
    "            WHERE\n",
    "              td.transaction_date >='{}'\n",
    "            AND  \n",
    "                td.transaction_date < '{}'\n",
    "              AND cbs.customer_identifier IS NOT NULL\n",
    "              AND ( td.sku_id is NOT NULL OR td.line_object_description IN ('OMS Sales Tax',\n",
    "'S6 Special Order T2 Sales Tax',\n",
    "'S6 T2 Sales Tax',\n",
    "'-Order T2 Sales Tax',\n",
    "'OMS T2 Sales Tax',\n",
    "'S6 Sales Tax',\n",
    "'-Order Sales Tax',\n",
    "'S6 Special Order Sales Tax'))\n",
    "            GROUP BY cbs.customer_identifier\n",
    "          ) a\n",
    "      ) b\n",
    "    ORDER BY RFM DESC, AmountPerWeek DESC, total_amount DESC\n",
    "\"\"\".format(dt_start, dt_end))\n",
    "    \n",
    "\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    trFrame = pd.read_sql_query(query, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    run_time = (end_time-start_time)/60\n",
    "\n",
    "    print(run_time)\n",
    "    return(trFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T23:18:36.074479Z",
     "start_time": "2019-01-28T23:18:36.071308Z"
    }
   },
   "outputs": [],
   "source": [
    "#[['2017/01/01', '2017/12/31'] \n",
    "date_list = [ ['2018/01/01', '2018/03/30'], ['2018/01/01', '2018/02/28'],\n",
    "            ['2018/01/01', '2018/06/30'], ['2018/01/01', '2018/01/31']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T19:05:56.624555Z",
     "start_time": "2019-03-07T19:05:56.601035Z"
    }
   },
   "outputs": [],
   "source": [
    "date_list = [['2018/01/01', '2019/02/28']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T19:47:24.037656Z",
     "start_time": "2019-03-07T19:06:09.206576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/01/01 2019/02/28\n",
      "39.60963578621546\n"
     ]
    }
   ],
   "source": [
    "totalTransDF = pd.DataFrame()\n",
    "\n",
    "for datePairs in date_list: \n",
    "    start_date = datePairs[0]\n",
    "    end_date = datePairs[1]\n",
    "    print(start_date, end_date)\n",
    "    tempDF = SQL_Query(start_date, end_date, 'Dhananjay.Kumar','password1!')\n",
    "    \n",
    "    start_date_str = str(start_date)\n",
    "    start_date_str = start_date_str.replace(\"/\", \"_\")\n",
    "    end_date_str = str(end_date)\n",
    "    end_date_str = end_date_str.replace(\"/\", \"_\")\n",
    "    tempDF['period']= start_date_str + '_'+end_date_str\n",
    "    tempDF.to_csv(r'/Users/sanjaygopinath/Documents/Data/Churn_Analysis/'+start_date_str+'_'+ end_date_str+'.csv')\n",
    "    #dfList = [totalTransDF, tempDF]\n",
    "    #totalTransDF = pd.concat(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T20:35:47.493224Z",
     "start_time": "2019-03-07T20:35:47.431322Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-02-02 00:00:00')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempDF.LastOrderDate.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T01:17:29.936869Z",
     "start_time": "2018-10-31T01:17:28.454780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of dates that iterate from the first day of the year weekly\n",
    "dates = list()\n",
    "month = 11\n",
    "year = 2017\n",
    "day = 17\n",
    "first_day = datetime.date(year, month, day)\n",
    "while year <=2018:\n",
    "\n",
    "    num_days = calendar.monthrange(year, month)\n",
    "    print(num_days)\n",
    "    #first_day = datetime.date(year, month, day)\n",
    "    \n",
    "    #last_day = datetime.date(year, month, num_days[1])\n",
    "    #last_day = first_day + timedelta(days=num_days[1])\n",
    "    last_day = first_day + timedelta(days=1)\n",
    "    dates.append([first_day, last_day]) \n",
    "    first_day = first_day+timedelta(days=1)\n",
    "    month = last_day.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T01:17:39.711234Z",
     "start_time": "2018-10-31T01:17:39.707268Z"
    }
   },
   "outputs": [],
   "source": [
    "dates = list()\n",
    "first_day = datetime.date(2016, 11, 1)\n",
    "last_day = datetime.date(2017, 11, 23)\n",
    "\n",
    "dates.append([first_day, last_day]) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T20:15:28.143097Z",
     "start_time": "2018-10-30T20:15:28.132726Z"
    }
   },
   "outputs": [],
   "source": [
    "dates = dates[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T20:15:28.624816Z",
     "start_time": "2018-10-30T20:15:28.620566Z"
    }
   },
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T15:24:51.139296Z",
     "start_time": "2018-10-09T15:24:51.136663Z"
    }
   },
   "outputs": [],
   "source": [
    "dates[0][1] = datetime.date(2018, 9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T15:23:38.795639Z",
     "start_time": "2018-10-09T15:23:38.792060Z"
    }
   },
   "outputs": [],
   "source": [
    "for datePairs in dates: \n",
    "    print(datePairs)\n",
    "    start_date = datePairs\n",
    "    end_date = datePairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T15:23:53.001495Z",
     "start_time": "2018-10-09T15:23:52.996822Z"
    }
   },
   "outputs": [],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T04:00:38.433432Z",
     "start_time": "2018-10-31T01:17:51.789983Z"
    }
   },
   "outputs": [],
   "source": [
    "totalTransDF = pd.DataFrame()\n",
    "\n",
    "for datePairs in dates: \n",
    "    start_date = datePairs[0]\n",
    "    end_date = datePairs[1]\n",
    "    print(start_date, end_date)\n",
    "    tempDF = SQL_Query(start_date, end_date, 'Dhananjay.Kumar','password1!')\n",
    "    tempDF['period']= start_date\n",
    "    start_date_str = str(start_date)\n",
    "    tempDF.to_csv(r'/Users/sanjaygopinath/Documents/Data/Responsys/summary'+start_date_str+'.csv')\n",
    "    dfList = [totalTransDF, tempDF]\n",
    "    totalTransDF = pd.concat(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T20:45:24.743198Z",
     "start_time": "2018-10-30T20:45:24.740291Z"
    }
   },
   "outputs": [],
   "source": [
    "#save our daily data so we can then look at CLV for those who shop over the week including black friday\n",
    "#dailyTransDF = totalTransDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T20:40:40.934611Z",
     "start_time": "2018-10-30T20:40:40.886932Z"
    }
   },
   "outputs": [],
   "source": [
    "totalTransDF['period'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T20:40:16.470478Z",
     "start_time": "2018-10-30T20:40:16.344374Z"
    }
   },
   "outputs": [],
   "source": [
    "totalTransDF.groupby(totalTransDF['period']).agg(['mean', 'var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T19:40:31.958308Z",
     "start_time": "2018-10-30T19:40:31.936390Z"
    }
   },
   "outputs": [],
   "source": [
    "tempDF['total_amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T19:46:18.966748Z",
     "start_time": "2018-10-09T19:44:47.323265Z"
    }
   },
   "outputs": [],
   "source": [
    "tempDF.to_csv(r'sept17-sept18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T20:15:53.730189Z",
     "start_time": "2018-10-09T20:15:53.726917Z"
    }
   },
   "outputs": [],
   "source": [
    "del dfList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare our functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
